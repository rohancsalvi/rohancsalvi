---
title: "Robust framework for measuring and mitigating stereotypical biases in LLM"
excerpt: "Understanding stereotypes perception in LLMs and based on it developing effective framework to measure and mitigate biases<br/><img src='/images/robot_society_small.png'>"
collection: portfolio
---

Two focus areas of our project:

- Methodologies for bias evaluation and mitigation: Developing automatic prompt generation and innovative prompt-based tasks to measure and identify stereotypical biases in LLMs across varied contextual settings. Comparing the model generation on handcrafted prompts against automated prompts.
- Evaluation metrics: Creating a novel evaluation metric that analyses biases based on prompt-based generation by LLMs. We aim to create a metric that can view the bias from multiple lenses and have begun initial research by working on intersectional biases. Our evaluation will also consider the noise in prompts, model parameters, and their impact. This comprehensive approach will allow us to gauge and understand biases more accurately.

